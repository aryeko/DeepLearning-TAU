{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b71334b5-be58-41e6-ba21-3724a91ff866",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class Layer:\n",
    "    def __init__(self, W, b, activation, d_activation):\n",
    "        self._weights = W # W should be matrix outDim*inDim\n",
    "        self._bias = b # W should be vector outDim*1\n",
    "        self._activation = activation\n",
    "        self._d_activation = d_activation\n",
    "        \n",
    "    def forward(self, v_prev):\n",
    "        self._v_prev = v_prev\n",
    "        self._z = np.dot(self._weights, self._v_prev) + self._bias\n",
    "        self._V = self._activation(self._z)\n",
    "        \n",
    "        return self._V\n",
    "        \n",
    "    def backward(self, err_next):\n",
    "        self.G = np.multiply(self._d_activation(self._z), err_next)\n",
    "        self._w_grad = np.dot(self.G, self._v_prev.transpose())\n",
    "        \n",
    "        self._b_grad = np.dot(self.G, np.ones([self.G.shape[1], 1]))\n",
    "        \n",
    "        self._err = np.dot(self._weights.transpose(), err_next)\n",
    "                       \n",
    "        return self._err\n",
    "        \n",
    "    def step(self, rate):\n",
    "        self._weights -= rate*self._w_grad\n",
    "        self._bias -= rate*self._b_grad\n",
    "        \n",
    "    def predict(self, X):\n",
    "        Z = np.dot(self._weights, X) + self._bias\n",
    "        V = self._activation(Z)\n",
    "        \n",
    "        return V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "46bb15f3-36bb-434e-ab73-07d7959dba1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearLayer(Layer):\n",
    "    identity = lambda x: x\n",
    "    didentity = lambda x: 1\n",
    "    \n",
    "    def __init__(self, W, b):\n",
    "        super().__init__(W, b, LinearLayer.identity, LinearLayer.didentity)\n",
    "\n",
    "        \n",
    "class RelULayer(Layer):\n",
    "    RelU = lambda x: np.maximum(x,0)\n",
    "    dRelU = lambda x: (x > 0) * 1\n",
    "    \n",
    "    def __init__(self, W, b):\n",
    "        super().__init__(W, b, RelULayer.RelU, RelULayer.dRelU)\n",
    "        \n",
    "        \n",
    "class SigmoidLayer(Layer):\n",
    "    sigmoid = lambda x: 1/(1 + np.exp(-x))\n",
    "    dsigmoid = lambda x: x * (1 - x)\n",
    "    \n",
    "    def __init__(self, W, b):\n",
    "        super().__init__(W, b, SigmoidLayer.sigmoid, SigmoidLayer.dsigmoid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eeac58f2-c410-4e34-a05a-47cd3296f522",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Manually running the network with HW inputs\n",
    "\n",
    "X = np.array([[1],[2],[-1]])\n",
    "Y = np.array([[0]])\n",
    "\n",
    "W_1 = np.ones([2,3])\n",
    "b_1 = np.ones([2,1])\n",
    "L1 = RelULayer(W_1, b_1)\n",
    "\n",
    "W_2 = np.ones([2,2])\n",
    "b_2 = np.ones([2,1])\n",
    "L2 = RelULayer(W_2, b_2)\n",
    "\n",
    "W_3 = np.ones([1,2])\n",
    "b_3 = np.ones([1,1])\n",
    "L3 = LinearLayer(W_3, b_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "50387710-b08c-40fd-81f7-31bf0aaa62f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "v1 = L1.forward(X)\n",
    "v2 = L2.forward(v1)\n",
    "v3 = L3.forward(v2)\n",
    "y_hat = v3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "01116fe7-8544-40c0-97d5-4a120c8a0c7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = 2*(y_hat-Y)\n",
    "\n",
    "err3 = L3.backward(loss)\n",
    "err2 = L2.backward(err3)\n",
    "err1 = L1.backward(err2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5df44f8d-32fe-43d1-b7d7-d02fb8233691",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L1 W grad:\n",
      " [[ 60. 120. -60.]\n",
      " [ 60. 120. -60.]]\n",
      "L1 b grad:\n",
      " [[60.]\n",
      " [60.]]\n",
      "=========================\n",
      "L2 W grad:\n",
      " [[90. 90.]\n",
      " [90. 90.]]\n",
      "L2 b grad:\n",
      " [[30.]\n",
      " [30.]]\n",
      "=========================\n",
      "L3 W grad:\n",
      " [[210. 210.]]\n",
      "L3 b grad:\n",
      " [[30.]]\n"
     ]
    }
   ],
   "source": [
    "print(\"L1 W grad:\\n\", L1._w_grad)\n",
    "print(\"L1 b grad:\\n\", L1._b_grad)\n",
    "print(\"=========================\")\n",
    "print(\"L2 W grad:\\n\", L2._w_grad)\n",
    "print(\"L2 b grad:\\n\", L2._b_grad)\n",
    "print(\"=========================\")\n",
    "print(\"L3 W grad:\\n\", L3._w_grad)\n",
    "print(\"L3 b grad:\\n\", L3._b_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "97557e2a-8065-4d0a-9898-a8675e6d56a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BatchNormalizationLayer(LinearLayer):\n",
    "    def __init__(self, gamma, b, K):\n",
    "        super().__init__(gamma, b)\n",
    "        self._K = K # Number of batches\n",
    "        self._all_batches_means = None\n",
    "        self._all_batches_vars = None\n",
    "    \n",
    "    def _update_global_mean_var(self, batch_means, batch_vars):\n",
    "        if self._all_batches_means is None:\n",
    "            self._all_batches_means = batch_means / self._K\n",
    "            self._all_batches_vars = batch_vars / self._K\n",
    "        else:\n",
    "            self._all_batches_means += batch_means / self._K\n",
    "            self._all_batches_vars += batch_vars / self._K\n",
    "            \n",
    "    def _standardize_batch(self, X):\n",
    "        self._m = X.mean(axis=1).reshape([X.shape[0],1])\n",
    "        self._v = X.var(axis=1).reshape([X.shape[0],1])\n",
    "        X_stand = np.subtract(X,self._m)/np.sqrt(self._v + 1e-8)\n",
    "        self._update_global_mean_var(self._m, self._v)\n",
    "        \n",
    "        return X_stand\n",
    "                \n",
    "    def forward(self, v_prev):\n",
    "        self._v_prev = v_prev\n",
    "        self._z = self._standardize_batch(v_prev)\n",
    "        self._V = np.multiply(self._weights, self._z) + self._bias\n",
    "        \n",
    "        return self._V\n",
    "\n",
    "\n",
    "    def backward(self, err_next):\n",
    "        \n",
    "        self.G = err_next\n",
    "        self._b_grad = np.dot(self.G, np.ones([self.G.shape[1], 1]))\n",
    "        self._w_grad = np.dot(self.G, self._z.transpose())\n",
    "        self._w_grad = np.sum(self._w_grad, axis=1).reshape(self._b_grad.shape)\n",
    "        \n",
    "        self._err = np.multiply(self._weights, err_next)\n",
    "        # rescale the error for the previous layer\n",
    "        self._err = np.multiply(self._err, self._v)\n",
    "        self._err = np.add(self._err, self._m)\n",
    "                       \n",
    "        return self._err\n",
    "        \n",
    "        \n",
    "    def predict(self, X):\n",
    "        X_stand = np.subtract(X,self._all_batches_means)/np.sqrt(self._all_batches_vars)\n",
    "        \n",
    "        Z = np.multiply(self._weights, X_stand) + self._bias\n",
    "        \n",
    "        return Z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "bae26a18-aa83-4dd8-8033-7d609c0807bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NN:\n",
    "    def __init__(self, layers):\n",
    "        self._layers = layers\n",
    "        self._iter_loss = [np.inf]\n",
    "        \n",
    "    def train(self, X, Y, loss, d_loss, max_iterations=1000, rate=1e-5, convergece_threshold=1e-10, n_batches=1, decay_rate=None):       \n",
    "        X_batches = np.array_split(X.transpose(), n_batches)\n",
    "        Y_batches = np.array_split(Y.transpose(), n_batches)\n",
    "        \n",
    "        self._initial_learning_rate = rate\n",
    "                \n",
    "        for i in range(max_iterations):                \n",
    "            if decay_rate:\n",
    "                rate = self._initial_learning_rate * np.power(decay_rate, i/n_batches)\n",
    "            for X_b, Y_b in zip(X_batches, Y_batches):\n",
    "                out = X_b.transpose()\n",
    "                for l in self._layers:\n",
    "                    # print(l, \"\\n\", out,\"\\n=====\")\n",
    "                    out = l.forward(out)\n",
    "                                    \n",
    "                err = d_loss(out, Y_b.transpose())\n",
    "                for l in reversed(self._layers):\n",
    "                    # print(err)\n",
    "                    err = l.backward(err)\n",
    "                    l.step(rate)\n",
    "        \n",
    "            mean_loss = np.mean(loss(self.predict(X), Y))\n",
    "            self._iter_loss.append(mean_loss)\n",
    "            mean_loss_diff = np.abs(self._iter_loss[-1] - self._iter_loss[-2])\n",
    "            if mean_loss_diff < convergece_threshold:\n",
    "                return True\n",
    "            \n",
    "        return False\n",
    "    \n",
    "                \n",
    "    def predict(self, X):\n",
    "        pred = X\n",
    "        for l in self._layers:\n",
    "            pred = l.predict(pred)\n",
    "            \n",
    "        return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "292700ec-1b18-438e-bb0f-957e2ae51fdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "9482332d-1f83-4420-8212-a408db7403d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_train = 10000\n",
    "n_test = 1000\n",
    "n = n_train + n_test\n",
    "p = 4\n",
    "\n",
    "X = np.random.uniform(0, 1, [n, p])\n",
    "X_train, X_test = X[:n_train].transpose(), X[(n_train+1):].transpose()\n",
    "X = X.transpose()\n",
    "\n",
    "noise = np.random.normal(0, 1, n)\n",
    "Y = X[0] - 2*X[1] + 3*X[2] - 4*X[3] + noise\n",
    "Y = Y.reshape([n, 1])\n",
    "Y_train, Y_test = Y[:n_train].transpose(), Y[(n_train+1):].transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "6cfece49-ea19-49f8-a37e-6bdfc3d48375",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_hw_network(batch_norm=False, K=1):\n",
    "    W_1 = np.ones([2,4])\n",
    "    b_1 = np.ones([2,1])\n",
    "    L1 = RelULayer(W_1, b_1)\n",
    "\n",
    "    W_2 = np.ones([2,2])\n",
    "    b_2 = np.ones([2,1])\n",
    "    L2 = RelULayer(W_2, b_2)\n",
    "\n",
    "    W_3 = np.ones([1,2])\n",
    "    b_3 = np.ones([1,1])\n",
    "    L3 = LinearLayer(W_3, b_3)\n",
    "    \n",
    "    nn = NN([L1, L2, L3])\n",
    "    \n",
    "    if batch_norm:\n",
    "        bn_gamma_1 = np.ones([4,1])\n",
    "        bn_b_1 = np.ones([4,1])\n",
    "        BN1 = BatchNormalizationLayer(bn_gamma_1, bn_b_1, K)\n",
    "        \n",
    "        bn_gamma_2 = np.ones([2,1])\n",
    "        bn_b_2 = np.ones([2,1])\n",
    "        BN2 = BatchNormalizationLayer(bn_gamma_2, bn_b_2, K)\n",
    "        \n",
    "        bn_gamma_3 = np.ones([2,1])\n",
    "        bn_b_3 = np.ones([2,1])\n",
    "        BN3 = BatchNormalizationLayer(bn_gamma_3, bn_b_3, K)\n",
    "            \n",
    "        nn = NN([BN1, L1, BN2, L2, BN3, L3])\n",
    "            \n",
    "    return nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "b8195e50-0921-4ea2-a55c-aa7c239e49a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import perf_counter\n",
    "\n",
    "rss = lambda y_hat, y: np.power((y_hat - y), 2)\n",
    "d_rss = lambda y_hat, y: 2*(y_hat - y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "6bcd491d-15bb-48d6-9ca4-1fa4d1253134",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converged? True\n",
      "Test MSE: 3.5966303634881887\n",
      "Number of iterations: 54\n",
      "Elapsed time: 0.09442424999724608\n"
     ]
    }
   ],
   "source": [
    "t1_start = perf_counter()\n",
    "\n",
    "nn1 = get_hw_network()\n",
    "nn1_converged = nn1.train(X_train, Y_train, rss, d_rss)\n",
    "nn1_mse = np.mean(rss(nn1.predict(X_test), Y_test))\n",
    "\n",
    "t1_stop = perf_counter()\n",
    "\n",
    "print(\"Converged?\", nn1_converged)\n",
    "print(\"Test MSE:\", nn1_mse)\n",
    "print(\"Number of iterations:\", len(nn1._iter_loss))\n",
    "print(\"Elapsed time:\", t1_stop-t1_start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "83f11b1a-dd50-4d9c-b9d8-1bff0286bbe4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converged? True\n",
      "Test MSE: 3.595724746889135\n",
      "Number of iterations: 305\n",
      "Elapsed time: 0.3353979170060484\n"
     ]
    }
   ],
   "source": [
    "t1_start = perf_counter()\n",
    "\n",
    "nn2 = get_hw_network()\n",
    "nn2_converged = nn2.train(X_train, Y_train, rss, d_rss, decay_rate=0.96)\n",
    "nn2_mse = np.mean(rss(nn2.predict(X_test), Y_test))\n",
    "\n",
    "\n",
    "t1_stop = perf_counter()\n",
    "\n",
    "print(\"Converged?\", nn2_converged)\n",
    "print(\"Test MSE:\", nn2_mse)\n",
    "print(\"Number of iterations:\", len(nn2._iter_loss))\n",
    "print(\"Elapsed time:\", t1_stop-t1_start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "40d10502-7652-454d-b790-3214532964ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converged? False\n",
      "Test MSE: 0.974741370242531\n",
      "Number of iterations: 1001\n",
      "Elapsed time: 5.236490877003234\n"
     ]
    }
   ],
   "source": [
    "t1_start = perf_counter()\n",
    "\n",
    "nn3 = get_hw_network()\n",
    "nn3_converged = nn3.train(X_train, Y_train, rss, d_rss, n_batches=50)\n",
    "nn3_mse = np.mean(rss(nn3.predict(X_test), Y_test))\n",
    "\n",
    "\n",
    "t1_stop = perf_counter()\n",
    "\n",
    "print(\"Converged?\", nn3_converged)\n",
    "print(\"Test MSE:\", nn3_mse)\n",
    "print(\"Number of iterations:\", len(nn3._iter_loss))\n",
    "print(\"Elapsed time:\", t1_stop-t1_start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "860bf021-04f8-4d7c-bdfe-e42fc3ea7a48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converged? True\n",
      "Test MSE: 0.974111502140585\n",
      "Number of iterations: 3361\n",
      "Elapsed time: 18.763103591998515\n"
     ]
    }
   ],
   "source": [
    "t1_start = perf_counter()\n",
    "\n",
    "nn3 = get_hw_network()\n",
    "nn3_converged = nn3.train(X_train, Y_train, rss, d_rss, n_batches=50, max_iterations=10000)\n",
    "nn3_mse = np.mean(rss(nn3.predict(X_test), Y_test))\n",
    "\n",
    "\n",
    "t1_stop = perf_counter()\n",
    "\n",
    "print(\"Converged?\", nn3_converged)\n",
    "print(\"Test MSE:\", nn3_mse)\n",
    "print(\"Number of iterations:\", len(nn3._iter_loss))\n",
    "print(\"Elapsed time:\", t1_stop-t1_start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "4650f37a-078d-47e8-95a5-6951cfce6841",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converged? True\n",
      "Test MSE: 3.280063487388046\n",
      "Number of iterations: 1078\n",
      "Elapsed time: 20.133264133997727\n"
     ]
    }
   ],
   "source": [
    "t1_start = perf_counter()\n",
    "\n",
    "nn4 = get_hw_network(batch_norm=True, K=50)\n",
    "nn4_converged = nn4.train(X_train, Y_train, rss, d_rss, n_batches=50, max_iterations=10000)\n",
    "nn4_mse = np.mean(rss(nn4.predict(X_test), Y_test))\n",
    "\n",
    "\n",
    "t1_stop = perf_counter()\n",
    "\n",
    "print(\"Converged?\", nn4_converged)\n",
    "print(\"Test MSE:\", nn4_mse)\n",
    "print(\"Number of iterations:\", len(nn4._iter_loss))\n",
    "print(\"Elapsed time:\", t1_stop-t1_start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "4213a53a-0263-4fa8-98da-51d7e309a657",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt \n",
    "\n",
    "plt.title(\"Matplotlib demo\") \n",
    "plt.xlabel(\"x axis caption\") \n",
    "plt.ylabel(\"y axis caption\") \n",
    "plt.plot(nn4._iter_loss[1:]) \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "108e4a6b-549b-4ad9-ad91-32ae713da663",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
